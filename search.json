[
  {
    "objectID": "1b.indic_normalizer.html",
    "href": "1b.indic_normalizer.html",
    "title": "Indic Languages Normalizer",
    "section": "",
    "text": "This code is from: https://github.com/anoopkunchukuttan/indic_nlp_library\nAlso use Indic Numtowords: https://github.com/raj-sutariya/indic-num2words, https://github.com/AI4Bharat/indic-numtowords\nThis code has been modified by Kurian to suit to Whisper-normalizer style of coding and the logic for Malayalam normalization is expanded beyond the Indic NLP library by Dr Kavya.\n\n\nsource\n\nNormalizerI\n\n NormalizerI ()\n\nThe normalizer classes do the following:  Some characters have multiple Unicode codepoints. The normalizer chooses a single standard representation * Some control characters are deleted * While typing using the Latin keyboard, certain typical mistakes occur which are corrected by the module Base class for normalizer. Performs some common normalization, which includes: * Byte order mark, word joiner, etc. removal * ZERO_WIDTH_NON_JOINER and ZERO_WIDTH_JOINER removal * ZERO_WIDTH_SPACE and NO_BREAK_SPACE replaced by spaces Script specific normalizers should derive from this class and override the normalize() method. They can call the super class ’normalize() method to avail of the common normalization*\n\nsource\n\n\nBaseNormalizer\n\n BaseNormalizer (lang, remove_nuktas=False, nasals_mode='do_nothing',\n                 do_normalize_chandras=False,\n                 do_normalize_vowel_ending=False)\n\nCommon class used in most of indic languages inherit from this code.\n\nsource\n\n\nDevanagariNormalizer\n\n DevanagariNormalizer (lang='hi', remove_nuktas=False,\n                       nasals_mode='do_nothing',\n                       do_normalize_chandras=False,\n                       do_normalize_vowel_ending=False)\n\nNormalizer for the Devanagari script. In addition to basic normalization by the super class,  Replaces the composite characters containing nuktas by their decomposed form * replace pipe character ‘|’ by poorna virama character * replace colon ‘:’ by visarga if the colon follows a charcter in this script*\n\nnorm = DevanagariNormalizer()\nTEST_RESULT = \"चीर धाराएं समुद्र तट पर लगकर लौटने वाली लहरों का प्रवाह होता है अक्सर एक चट्टान या इसी तरह के पदार्थों पर\"\nhi_text = \"चीर धाराएं समुद्र तट पर लगकर लौटने वाली लहरों का प्रवाह होता है अक्सर एक चट्टान या इसी तरह के पदार्थों पर\"\nnorm(hi_text)\n\n'चीर धाराएं समुद्र तट पर लगकर लौटने वाली लहरों का प्रवाह होता है अक्सर एक चट्टान या इसी तरह के पदार्थों पर'\n\n\n\nassert norm(hi_text) == TEST_RESULT\n\n\nsample_text = \"भारत का सकल घरेलू उत्पाद 1.5 ट्रिलियन अमेरिकी डॉलर है।\"\nnorm(sample_text)\n\n'भारत का सकल घरेलू उत्पाद एक.पाँच ट्रिलियन अमेरिकी डॉलर है।'\n\n\n\nsource\n\n\nHindiNormalizer\n\n HindiNormalizer (lang='hi', remove_nuktas=False,\n                  nasals_mode='do_nothing', do_normalize_chandras=False,\n                  do_normalize_vowel_ending=False, tts_mode=False)\n\nFork of Devanagiri normalizer. With additional changes for Hindi and tts_mode.\n\nnorm = HindiNormalizer(tts_mode=True)\nTEST_RESULT = \"चीर धाराएं समुद्र तट पर लगकर लौटने वाली लहरों का प्रवाह होता है अक्सर एक चट्टान या इसी तरह के पदार्थों पर\"\nhi_text = \"चीर धाराएं समुद्र तट पर लगकर लौटने वाली लहरों का प्रवाह होता है अक्सर एक चट्टान या इसी तरह के पदार्थों पर $134.5\"\nnorm(hi_text)\n\n'चीर धाराएं समुद्र तट पर लगकर लौटने वाली लहरों का प्रवाह होता है अक्सर एक चट्टान या इसी तरह के पदार्थों पर डॉलर एक सौ चौंतीस पॉइंट पाँच'\n\n\n\nnormalizer = HindiNormalizer(tts_mode=True)\noutput = normalizer(\"He spent Rs. 500 and $20 on groceries.\")\nprint(output)\n\nhe spent रुपये पाँच सौ and डॉलर बीस on groceries.\n\n\n\nnormalizer = HindiNormalizer(tts_mode=True)\noutput = normalizer(\n    \"Visit https://example.com or mail us at help@support.in & get 20% off!\"\n)\nprint(output)\n\nvisit एच टी टी पी एस कोलन स्लैश स्लैश e x a m p l e डॉट c o m or mail us at help at s u p p o r t डॉट i n  or  get बीस percent  off!\n\n\n\ntext = \"आज की तारीख में भारत में ₹100 अमेरिका में $1.1855 के बराबर है alexerws@gmail.com\"\nnormalizer(text)\n\n'आज की तारीख में भारत में रुपये एक सौ अमेरिका में डॉलर एक पॉइंट एक आठ पाँच पाँच के बराबर है alexerws at g m a i l डॉट c o m'\n\n\n\ntext = \"प्रश्न 8 चे उत्तर 17.825 आहे.\"\nnormalizer(text)\n\n'प्रश्न आठ चे उत्तर सत्रह पॉइंट आठ दो पाँच आहे.'\n\n\n\nsample_text = \"भारत का सकल घरेलू उत्पाद 1.5 ट्रिलियन अमेरिकी डॉलर है।\"\nnormalizer(sample_text)\n\n'भारत का सकल घरेलू उत्पाद एक पॉइंट पाँच ट्रिलियन अमेरिकी डॉलर है।'\n\n\n\nsource\n\n\nPunjabiNormalizer\n\n PunjabiNormalizer (lang='pa', remove_nuktas=False,\n                    nasals_mode='do_nothing', do_normalize_chandras=False,\n                    do_normalize_vowel_ending=False,\n                    do_canonicalize_addak=False,\n                    do_canonicalize_tippi=False,\n                    do_replace_vowel_bases=False, tts_mode=False)\n\nNormalizer for the Gurmukhi script. In addition to basic normalization by the super class,  Replaces the composite characters containing nuktas by their decomposed form * Replace the reserved character for poorna virama (if used) with the recommended generic Indic scripts poorna virama * replace pipe character ‘|’ by poorna virama character * replace colon ‘:’ by visarga if the colon follows a charcter in this script*\n\nnormalizer = PunjabiNormalizer(tts_mode=True)\npunjabi_text = \"ਪੰਜੀਵੀ ਜੀਡੀਪੀ 1.5 ਟ੍ਰੀਲੀਅਨ ਅਮਰੀਕਾ ਡੋਲਰ ਛੇ।\"\nnormalizer(punjabi_text)\n\n'ਪੰਜੀਵੀ ਜੀਡੀਪੀ ਇੱਕ ਪੌਇੰਟ ਪੰਜ ਟ੍ਰੀਲੀਅਨ ਅਮਰੀਕਾ ਡੋਲਰ ਛੇ।'\n\n\n\npunjabi_text = (\n    \"ਸਤਿ ਸ੍ਰੀ ਅਕਾਲ ਦੁਨੀਆਂ। 4 ਮਈ, 2025 ਨੂੰ ਰਿਲੀਜ਼ ਹੋਏ ਪੰਜਾਬੀ ਨੋਰਮਲਾਈਜ਼ਰ ਵਿੱਚ ਤੁਹਾਡਾ ਸਵਾਗਤ ਹੈ।\"\n)\nnormalizer(punjabi_text)\n\n'ਸਤਿ ਸ੍ਰੀ ਅਕਾਲ ਦੁਨੀਆਂ। ਚਾਰ ਮਈ, ਦੋ ਹਜ਼ਾਰ ਪੱਚੀ ਨੂੰ ਰਿਲੀਜ਼ ਹੋਏ ਪੰਜਾਬੀ ਨੋਰਮਲਾਈਜ਼ਰ ਵਿੱਚ ਤੁਹਾਡਾ ਸਵਾਗਤ ਹੈ।'\n\n\n\nsource\n\n\nTeluguNormalizer\n\n TeluguNormalizer (lang='te', remove_nuktas=False,\n                   nasals_mode='do_nothing', do_normalize_chandras=False,\n                   do_normalize_vowel_ending=False, tts_mode=False)\n\nNormalizer for the Teluguscript. In addition to basic normalization by the super class,  Replace the reserved character for poorna virama (if used) with the recommended generic Indic scripts poorna virama * canonicalize two-part dependent vowel signs * replace colon ‘:’ by visarga if the colon follows a charcter in this script*\n\nnorm = TeluguNormalizer()\nte_text = \"భారతదేశ జీడీపీ 1.5 ట్రిలియన్ అమెరికా డాలర్లు.\"\nnorm(te_text)\n\n'భారతదేశ జీడీపీ ఒకటి.ఐదు ట్రిలియన్ అమెరికా డాలర్లు.'\n\n\n\nnorm = TeluguNormalizer(tts_mode=True)\nnorm(te_text)\n\n'భారతదేశ జీడీపీ ఒకటి పాయింట్ ఐదు ట్రిలియన్ అమెరికా డాలర్లు.'\n\n\n\nsource\n\n\nGujaratiNormalizer\n\n GujaratiNormalizer (lang='gu', remove_nuktas=False,\n                     nasals_mode='do_nothing',\n                     do_normalize_chandras=False,\n                     do_normalize_vowel_ending=False, tts_mode=False)\n\nNormalizer for the Gujarati script. In addition to basic normalization by the super class,  Replace the reserved character for poorna virama (if used) with the recommended generic Indic scripts poorna virama * replace colon ‘:’ by visarga if the colon follows a charcter in this script*\n\nnorm = GujaratiNormalizer(tts_mode=True)\ngujarati_text = \"ભારતનો જીડીપી 1.5 ટ્રિલિયન અમેરિકન ડોલર છે.\"\nnorm(gujarati_text)\n\n'ભારતનો જીડીપી એક પોઈન્ટ પાંચ ટ્રિલિયન અમેરિકન ડોલર છે.'\n\n\n\nsource\n\n\nOdiaNormalizer\n\n OdiaNormalizer (lang='or', remove_nuktas=False, nasals_mode='do_nothing',\n                 do_normalize_chandras=False,\n                 do_normalize_vowel_ending=False, do_remap_wa=False,\n                 tts_mode=False)\n\nNormalizer for the Oriya script. In addition to basic normalization by the super class,  Replaces the composite characters containing nuktas by their decomposed form * Replace the reserved character for poorna virama (if used) with the recommended generic Indic scripts poorna virama * Canonicalize two part dependent vowels * Replace ‘va’ with ‘ba’ * replace pipe character ‘|’ by poorna virama character * replace colon ‘:’ by visarga if the colon follows a charcter in this script*\n\nnorm = OdiaNormalizer(tts_mode=True)\nodia_text = \"ଭାରତର ଜିଡିପି 1.5 ଟ୍ରିଲିଅନ୍ ଆମେରିକୀୟ ଡଲାର ଅଟେ।\"\nnorm(odia_text)\n\n'ଭାରତର ଜିଡିପି ଏକ ପଏଣ୍ଟ ପାଞ୍ଚ ଟ୍ରିଲିଅନ୍ ଆମେରିକୀୟ ଡଲାର ଅଟେ।'\n\n\n\nsource\n\n\nBengaliNormalizer\n\n BengaliNormalizer (lang='bn', remove_nuktas=False,\n                    nasals_mode='do_nothing', do_normalize_chandras=False,\n                    do_normalize_vowel_ending=False,\n                    do_remap_assamese_chars=False, tts_mode=False)\n\nNormalizer for the Bengali script. In addition to basic normalization by the super class,  Replaces the composite characters containing nuktas by their decomposed form * Replace the reserved character for poorna virama (if used) with the recommended generic Indic scripts poorna virama * Canonicalize two part dependent vowels * replace pipe character ‘|’ by poorna virama character * replace colon ‘:’ by visarga if the colon follows a charcter in this script*\n\nnorm = BengaliNormalizer(tts_mode=True)\n\nTEST_RESULT = \"ভারতের জিডিপি ১.৫ ট্রিলিয়ন মার্কিন ডলার।\"  # Claude generated output\nbn_text = \"ভারতের জিডিপি 1.5 ট্রিলিয়ন মার্কিন ডলার।\"\nnorm(bn_text)\n\n'ভারতের জিডিপি এক পয়েন্ট পাঁচ ট্রিলিয়ন মার্কিন ডলার।'\n\n\n\nsource\n\n\nTamilNormalizer\n\n TamilNormalizer (lang='ta', remove_nuktas=False,\n                  nasals_mode='do_nothing', do_normalize_chandras=False,\n                  do_normalize_vowel_ending=False, tts_mode=False)\n\nNormalizer for the Tamil script. In addition to basic normalization by the super class,  Replace the reserved character for poorna virama (if used) with the recommended generic Indic scripts poorna virama * canonicalize two-part dependent vowel signs * replace colon ‘:’ by visarga if the colon follows a charcter in this script*\n\nnorm = TamilNormalizer(tts_mode=True)\nta_text = \"இந்தியாவின் மொத்த உள்நாட்டு உற்பத்தி 1.5 டிரில்லியன் அமெரிக்க டாலர்.\"\nnorm(ta_text)\n\n'இந்தியாவின் மொத்த உள்நாட்டு உற்பத்தி ஒன்று பாயிண்ட் ஐந்து டிரில்லியன் அமெரிக்க டாலர்.'\n\n\n\nnorm = TamilNormalizer(tts_mode=True)\nta_text = \"அவர் Rs. 500 மற்றும் $20 க்கு உணவுப்பொருட்கள் வாங்கினார். இணையதளம்: www.amazon.in.\"\nnorm(ta_text)\n\n'அவர் ரூபாய் ஐநூறு மற்றும் டாலர் இருபது க்கு உணவுப்பொருட்கள் வாங்கினார். இணையதளம்ஃ w w w டாட் a m a z o n டாட் i n.'\n\n\n\nsource\n\n\nKannadaNormalizer\n\n KannadaNormalizer (lang='kn', remove_nuktas=False,\n                    nasals_mode='do_nothing', do_normalize_chandras=False,\n                    do_normalize_vowel_ending=False, tts_mode=False)\n\nNormalizer for the Kannada script. In addition to basic normalization by the super class,  Replace the reserved character for poorna virama (if used) with the recommended generic Indic scripts poorna virama * canonicalize two-part dependent vowel signs * replace colon ‘:’ by visarga if the colon follows a charcter in this script*\n\nnorm = KannadaNormalizer(tts_mode=True)\nkannada_text = \"ಭಾರತದ ಜಿಡಿಪಿ 1.5 ಟ್ರಿಲಿಯನ್ ಅಮೇರಿಕನ್ ಡಾಲರ್ ಆಗಿದೆ.\"\nnorm(kannada_text)\n\n'ಭಾರತದ ಜಿಡಿಪಿ ಒಂದು ಪಾಯಿಂಟ್ ಐದು ಟ್ರಿಲಿಯನ್ ಅಮೇರಿಕನ್ ಡಾಲರ್ ಆಗಿದೆ.'\n\n\n\nsource\n\n\nMalayalamNormalizer\n\n MalayalamNormalizer (lang='ml', remove_nuktas=False,\n                      nasals_mode='do_nothing',\n                      do_normalize_chandras=False,\n                      do_normalize_vowel_ending=False,\n                      do_canonicalize_chillus=False,\n                      do_correct_geminated_T=False, tts_mode=False)\n\nNormalizer for the Malayalam script. In addition to basic normalization by the super class,  Replace the reserved character for poorna virama (if used) with the recommended generic Indic scripts poorna virama * canonicalize two-part dependent vowel signs * Change from old encoding of chillus (till Unicode 5.0) to new encoding * replace colon ‘:’ by visarga if the colon follows a charcter in this script*\n\nTests\n\nnormalizer = MalayalamNormalizer()\n\n\nTEST_RESULT = \"എന്റെ കമ്പ്യൂട്ടറിന് എന്റെ ഭാഷ.\"\ntext_result = normalizer(\"എന്റെ കമ്പ്യൂട്ടറിനു് എന്റെ ഭാഷ.\")\n\nassert text_result == TEST_RESULT\n\n\nTESTCASE_RESULT = \"യുപിഎ ഭരണകാലത്തെ സാമ്പത്തിക വീഴ്ച; ധവളപത്രം ഇറക്കാൻ കേന്ദ്രസർക്കാർ.\\n\\nയുപിഎ സർക്കാരിന്റെ കാലത്തെ ധനവിനിയോഗത്തിലെ വീഴ്ചകൾ വ്യക്തമാക്കുന്ന ധവളപത്രം ഇറക്കാൻ കേന്ദ്രസർക്കാർ തീരുമാനം. ബജറ്റ് സമ്മേളനം ഇതിനായി ഒരു ദിവസം കൂടി നീട്ടും. വിഹിതങ്ങൾ എപ്രകാരം തെറ്റായി വിനിയോഗിക്കപ്പെട്ടു എന്നതുൾപ്പെടെയുള്ള കാര്യങ്ങൾ വിശദീകരിക്കാനാണ് കേന്ദ്രസർക്കാർ നീക്കം.\\n\\n\"\ntext_result = normalizer(\n    \"\"\"യുപിഎ ഭരണകാലത്തെ സാമ്പത്തിക വീഴ്ച; ധവളപത്രം ഇറക്കാൻ കേന്ദ്രസർക്കാർ.\n\nയുപിഎ സർക്കാരിന്റെ കാലത്തെ ധനവിനിയോഗത്തിലെ വീഴ്ചകൾ വ്യക്തമാക്കുന്ന ധവളപത്രം ഇറക്കാൻ കേന്ദ്രസർക്കാർ തീരുമാനം. ബജറ്റ് സമ്മേളനം ഇതിനായി ഒരു ദിവസം കൂടി നീട്ടും. വിഹിതങ്ങൾ എപ്രകാരം തെറ്റായി വിനിയോഗിക്കപ്പെട്ടു എന്നതുൾപ്പെടെയുള്ള കാര്യങ്ങൾ വിശദീകരിക്കാനാണ് കേന്ദ്രസർക്കാർ നീക്കം.\n\n\"\"\"\n)\ntext_result\n\n'യുപിഎ ഭരണകാലത്തെ സാമ്പത്തിക വീഴ്ച; ധവളപത്രം ഇറക്കാൻ കേന്ദ്രസർക്കാർ.\\n\\nയുപിഎ സർക്കാരിന്റെ കാലത്തെ ധനവിനിയോഗത്തിലെ വീഴ്ചകൾ വ്യക്തമാക്കുന്ന ധവളപത്രം ഇറക്കാൻ കേന്ദ്രസർക്കാർ തീരുമാനം. ബജറ്റ് സമ്മേളനം ഇതിനായി ഒരു ദിവസം കൂടി നീട്ടും. വിഹിതങ്ങൾ എപ്രകാരം തെറ്റായി വിനിയോഗിക്കപ്പെട്ടു എന്നതുൾപ്പെടെയുള്ള കാര്യങ്ങൾ വിശദീകരിക്കാനാണ് കേന്ദ്രസർക്കാർ നീക്കം.\\n\\n'\n\n\n\nassert text_result == TESTCASE_RESULT\n\n\nnormalizer = MalayalamNormalizer(tts_mode=True)\nmalaylam_text = \"ഇന്ത്യയുടെ ജിഡിപി 1.5 ട്രില്യൺ യുഎസ് ഡോളറാണ്.\"\nTESTCASE_RESULT = \"ഇന്ത്യയുടെ ജിഡിപി ഒന്ന് പോയിന്റ് അഞ്ച് ട്രില്യൺ യുഎസ് ഡോളറാണ്.\"\ntext_result = normalizer(malaylam_text)\ntext_result\n\n'ഇന്ത്യയുടെ ജിഡിപി ഒന്ന് പോയിന്റ് അഞ്ച് ട്രില്യൺ യുഎസ് ഡോളറാണ്.'\n\n\n\nassert text_result == TESTCASE_RESULT\n\n\nTESTCASE_RESULT = \"ദുഃഖം\"\ntext_result = normalizer(\"ദു:ഖം\")\ntext_result\n\n'ദുഃഖം'\n\n\n\nassert text_result == TESTCASE_RESULT\n\n\nTESTCASE_RESULT = \"എന്റെ\"\ntext_result = normalizer(\"എൻറെ\")\ntext_result\n\n# Still fails\n\n'എൻറെ'\n\n\n\nnormalizer(\n    \"1000 രൂപ കൊടുത്തു. അയാൾ 500 ഡോളറിനും 20 ഡോളറിനും പലചരക്ക് സാധനങ്ങൾ വാങ്ങി. വെബ്സൈറ്റ്: www.amazon.in.\"\n)\n\n'ആയിരം രൂപ കൊടുത്തു. അയാൾ അഞ്ഞൂറ് ഡോളറിനും ഇരുപത് ഡോളറിനും പലചരക്ക് സാധനങ്ങൾ വാങ്ങി. വെബ്സൈറ്റ്ഃ w w w ഡോട്ട് a m a z o n ഡോട്ട് i n.'\n\n\n\n# TESTCASE_RESULT  = \"കാണ്മാനില്ല\"\n# text_result = normalizer(\"കാണ്മാനില്ല\")\n# text_result\n\n# Still fails",
    "crumbs": [
      "Indic Languages Normalizer"
    ]
  },
  {
    "objectID": "english.html",
    "href": "english.html",
    "title": "WhisperNormalizer English Module",
    "section": "",
    "text": "As per the text normalization/standardization approach Appendix Section C pp.21 the paper Robust Speech Recognition via Large-Scale Weak Supervision. The EnglishTextNormalizer does the following functionality:\n\nRemove any phrases between matching brackets ([, ]).\nRemove any phrases between matching parentheses ((, )).\nRemove any of the following words: hmm, mm, mhm, mmm, uh, um\nRemove whitespace characters that comes before an apostrophe ’\nConvert standard or informal contracted forms of English into the original form.\nRemove commas (,) between digits\nRemove periods (.) not followed by numbers\nRemove symbols as well as diacritics from the text, where symbols are the characters with the Unicode category starting with M, S, or P, except period, percent, and currency symbols that may be detected in the next step.\nDetect any numeric expressions of numbers and currencies and replace with a form using Arabic numbers, e.g. “Ten thousand dollars” → “$10000”.\nConvert British spellings into American spellings.\nRemove remaining symbols that are not part of any numeric expressions.\nReplace any successive whitespace characters with a space.\n\n\nsource\n\n\n\n EnglishNumberNormalizer ()\n\n*Convert any spelled-out numbers into arabic numbers, while handling:\n\nremove any commas\nkeep the suffixes such as: 1960s, 274th, 32nd, etc.\nspell out currency symbols after the number. e.g. $20 million -&gt; 20000000 dollars\nspell out one and ones\ninterpret successive single-digit numbers as nominal: one oh one -&gt; 101*\n\n\nsource\n\n\n\n\n EnglishSpellingNormalizer ()\n\n*Applies British-American spelling mappings as listed in [1].\n[1] https://web.archive.org/web/20230326222449/https://www.tysto.com/uk-us-spelling-list.html*\n\nn = EnglishSpellingNormalizer()\nn(\"accessorise\")\n\n'accessorize'\n\n\n\nsource\n\n\n\n\n EnglishTextNormalizer ()\n\n*Applies all the rules for normalizing English text as mentioned in OpenAI whisper paper. As per the text normalization/standardization approach Appendix Section C pp.21 the paper Robust Speech Recognition via Large-Scale Weak Supervision. The EnglishTextNormalizer does the following functionality:\n\nRemove any phrases between matching brackets ([, ]).\nRemove any phrases between matching parentheses ((, )).\nRemove any of the following words: hmm, mm, mhm, mmm, uh, um\nRemove whitespace characters that comes before an apostrophe ’\nConvert standard or informal contracted forms of English into the original form.\nRemove commas (,) between digits\nRemove periods (.) not followed by numbers\nRemove symbols as well as diacritics from the text, where symbols are the characters with the Unicode category starting with M, S, or P, except period, percent, and currency symbols that may be detected in the next step.\nDetect any numeric expressions of numbers and currencies and replace with a form using Arabic numbers, e.g. “Ten thousand dollars” → “$10000”.\nConvert British spellings into American spellings.\nRemove remaining symbols that are not part of any numeric expressions.\nReplace any successive whitespace characters with a space.*",
    "crumbs": [
      "WhisperNormalizer English Module"
    ]
  },
  {
    "objectID": "english.html#what-does-this-module-do",
    "href": "english.html#what-does-this-module-do",
    "title": "WhisperNormalizer English Module",
    "section": "",
    "text": "As per the text normalization/standardization approach Appendix Section C pp.21 the paper Robust Speech Recognition via Large-Scale Weak Supervision. The EnglishTextNormalizer does the following functionality:\n\nRemove any phrases between matching brackets ([, ]).\nRemove any phrases between matching parentheses ((, )).\nRemove any of the following words: hmm, mm, mhm, mmm, uh, um\nRemove whitespace characters that comes before an apostrophe ’\nConvert standard or informal contracted forms of English into the original form.\nRemove commas (,) between digits\nRemove periods (.) not followed by numbers\nRemove symbols as well as diacritics from the text, where symbols are the characters with the Unicode category starting with M, S, or P, except period, percent, and currency symbols that may be detected in the next step.\nDetect any numeric expressions of numbers and currencies and replace with a form using Arabic numbers, e.g. “Ten thousand dollars” → “$10000”.\nConvert British spellings into American spellings.\nRemove remaining symbols that are not part of any numeric expressions.\nReplace any successive whitespace characters with a space.\n\n\nsource\n\n\n\n EnglishNumberNormalizer ()\n\n*Convert any spelled-out numbers into arabic numbers, while handling:\n\nremove any commas\nkeep the suffixes such as: 1960s, 274th, 32nd, etc.\nspell out currency symbols after the number. e.g. $20 million -&gt; 20000000 dollars\nspell out one and ones\ninterpret successive single-digit numbers as nominal: one oh one -&gt; 101*\n\n\nsource\n\n\n\n\n EnglishSpellingNormalizer ()\n\n*Applies British-American spelling mappings as listed in [1].\n[1] https://web.archive.org/web/20230326222449/https://www.tysto.com/uk-us-spelling-list.html*\n\nn = EnglishSpellingNormalizer()\nn(\"accessorise\")\n\n'accessorize'\n\n\n\nsource\n\n\n\n\n EnglishTextNormalizer ()\n\n*Applies all the rules for normalizing English text as mentioned in OpenAI whisper paper. As per the text normalization/standardization approach Appendix Section C pp.21 the paper Robust Speech Recognition via Large-Scale Weak Supervision. The EnglishTextNormalizer does the following functionality:\n\nRemove any phrases between matching brackets ([, ]).\nRemove any phrases between matching parentheses ((, )).\nRemove any of the following words: hmm, mm, mhm, mmm, uh, um\nRemove whitespace characters that comes before an apostrophe ’\nConvert standard or informal contracted forms of English into the original form.\nRemove commas (,) between digits\nRemove periods (.) not followed by numbers\nRemove symbols as well as diacritics from the text, where symbols are the characters with the Unicode category starting with M, S, or P, except period, percent, and currency symbols that may be detected in the next step.\nDetect any numeric expressions of numbers and currencies and replace with a form using Arabic numbers, e.g. “Ten thousand dollars” → “$10000”.\nConvert British spellings into American spellings.\nRemove remaining symbols that are not part of any numeric expressions.\nReplace any successive whitespace characters with a space.*",
    "crumbs": [
      "WhisperNormalizer English Module"
    ]
  },
  {
    "objectID": "english.html#testing-englishtextnormalizer",
    "href": "english.html#testing-englishtextnormalizer",
    "title": "WhisperNormalizer English Module",
    "section": "Testing EnglishTextNormalizer",
    "text": "Testing EnglishTextNormalizer\n\nnormalizer = EnglishTextNormalizer()\nnormalizer(\"I'm a little teapot, short and stout. Tip me over and pour me out!\")\n\n'i am a little teapot short and stout tip me over and pour me out'\n\n\n\narticle_text = \"\"\"Language is like a map that we use to navigate the world, but it’s also like a prison that keeps us from seeing what’s beyond the walls.\n\nBut what if there was a way to break out of this prison, to expand our map, to explore new worlds with new words? This is the possibility and the challenge offered by instruction tuned language models like GPT 4, a cutting-edge technology that uses artificial neural networks to generate natural language texts based on user inputs.\n\nGPT 4 can write anything from essays to novels to poems to tweets to code to recipes to jokes to lyrics to whatever you want. It can even write things that don’t exist yet, things that no human has ever thought of or said before.\n\nAs Wittgenstein’s quote suggests, language is a source of limitation and liberation. GPT 4 pushes this idea to the extreme by giving us access to unlimited language.\n\nThis could be the most significant new technology in modern history because it has the potential to change many domains and industries. From education to entertainment, from journalism to justice, from science to art, these models could enable new forms of learning, storytelling, reporting, reasoning, discovery, and creation.\n\nThey could also create new ethical, social, and cultural challenges that require careful reflection and regulation. How we use this technology will depend on how we recognize its implications for ourselves and others.\n\nThis technology is a form of “Artificial Intelligence”. The word “intelligence” derives from inter- (“between”) and legere (“to choose, pick out, read”). To be intelligent, then, is to be able to choose between things, to pick out what matters, to read what is written. Intelligence is not just a quantity or a quality; it is an activity, a process, a practice. It is something that we do with our minds and our words.\n\nBut when we let GPT 4 do this for us, are we not abdicating our intelligence? Are we not letting go of our ability to choose, to pick out, to read? Are we not becoming passive consumers of language instead of active producers?\n\"\"\"\nnormalizer(article_text)\n\n'language is like a map that we use to navigate the world but it s also like a prison that keeps us from seeing what s beyond the walls but what if there was a way to break out of this prison to expand our map to explore new worlds with new words this is the possibility and the challenge offered by instruction tuned language models like gpt 4 a cutting edge technology that uses artificial neural networks to generate natural language texts based on user inputs gpt 4 can write anything from essays to novels to poems to tweets to code to recipes to jokes to lyrics to whatever you want it can even write things that don t exist yet things that no human has ever thought of or said before as wittgenstein s quote suggests language is a source of limitation and liberation gpt 4 pushes this idea to the extreme by giving us access to unlimited language this could be the most significant new technology in modern history because it has the potential to change many domains and industries from education to entertainment from journalism to justice from science to art these models could enable new forms of learning storytelling reporting reasoning discovery and creation they could also create new ethical social and cultural challenges that require careful reflection and regulation how we use this technology will depend on how we recognize its implications for ourselves and others this technology is a form of artificial intelligence the word intelligence derives from inter and legere to be intelligent then is to be able to choose between things to pick out what matters to read what is written intelligence is not just a quantity or a quality it is an activity a process a practice it is something that we do with our minds and our words but when we let gpt 4 do this for us are we not abdicating our intelligence are we not letting go of our ability to choose to pick out to read are we not becoming passive consumers of language instead of active producers'",
    "crumbs": [
      "WhisperNormalizer English Module"
    ]
  },
  {
    "objectID": "basic.html",
    "href": "basic.html",
    "title": "WhisperNormalizer Base Module",
    "section": "",
    "text": "As per the text normalization/standardization approach mentioned in Appendix Section C pp.21 in the paper Robust Speech Recognition via Large-Scale Weak Supervision. The BasicTextNormalizer does the following functionality:\n\nRemove any phrases between matching brackets ([, ]).\nRemove any phrases between matching parentheses ((, )).\nReplace any markers, symbols, and punctuation characters with a space, i.e. when the Unicode category of each character in the NFKC-normalized string starts with M, S, or P.\nmake the text lowercase.\nreplace any successive whitespace characters with a space\n\n\nsource\n\n\n\n remove_symbols (s:str)\n\nReplace any other markers, symbols, punctuations with a space, keeping diacritics\n\nsource\n\n\n\n\n remove_symbols_and_diacritics (s:str, keep='')\n\nReplace any other markers, symbols, and punctuations with a space, and drop any diacritics (category ‘Mn’ and some manual mappings)\n\n# #| export\n# add_docs(BasicTextNormalizer, \"Initialize BasicTextNormalizer\",\n#          # remove_diacritics=\"Replace any other markers, symbols, and punctuations with a space and drop any diacritics\",\n#          # split_letters=\"It uses a regular expression \\X to find all Unicode graphemes (extended grapheme clusters) in the string s and join them together by space\",\n#          __call__=\"Call string s and apply normalizer with `BasicTextNormalizer`\"\n#         )",
    "crumbs": [
      "WhisperNormalizer Base Module"
    ]
  },
  {
    "objectID": "basic.html#what-does-this-module-do",
    "href": "basic.html#what-does-this-module-do",
    "title": "WhisperNormalizer Base Module",
    "section": "",
    "text": "As per the text normalization/standardization approach mentioned in Appendix Section C pp.21 in the paper Robust Speech Recognition via Large-Scale Weak Supervision. The BasicTextNormalizer does the following functionality:\n\nRemove any phrases between matching brackets ([, ]).\nRemove any phrases between matching parentheses ((, )).\nReplace any markers, symbols, and punctuation characters with a space, i.e. when the Unicode category of each character in the NFKC-normalized string starts with M, S, or P.\nmake the text lowercase.\nreplace any successive whitespace characters with a space\n\n\nsource\n\n\n\n remove_symbols (s:str)\n\nReplace any other markers, symbols, punctuations with a space, keeping diacritics\n\nsource\n\n\n\n\n remove_symbols_and_diacritics (s:str, keep='')\n\nReplace any other markers, symbols, and punctuations with a space, and drop any diacritics (category ‘Mn’ and some manual mappings)\n\n# #| export\n# add_docs(BasicTextNormalizer, \"Initialize BasicTextNormalizer\",\n#          # remove_diacritics=\"Replace any other markers, symbols, and punctuations with a space and drop any diacritics\",\n#          # split_letters=\"It uses a regular expression \\X to find all Unicode graphemes (extended grapheme clusters) in the string s and join them together by space\",\n#          __call__=\"Call string s and apply normalizer with `BasicTextNormalizer`\"\n#         )",
    "crumbs": [
      "WhisperNormalizer Base Module"
    ]
  },
  {
    "objectID": "basic.html#testing-basic-normalizer",
    "href": "basic.html#testing-basic-normalizer",
    "title": "WhisperNormalizer Base Module",
    "section": "Testing Basic Normalizer",
    "text": "Testing Basic Normalizer\n\nnormalizer = BasicTextNormalizer()\nnormalizer(\"എന്റെ കമ്പ്യൂട്ടറിനു് എന്റെ ഭാഷ\")\n\n'എന റ കമ പ യ ട ടറ ന എന റ ഭ ഷ'\n\n\n\narticle_text = \"\"\"Language is like a map that we use to navigate the world, but it’s also like a prison that keeps us from seeing what’s beyond the walls.\n\nBut what if there was a way to break out of this prison, to expand our map, to explore new worlds with new words? This is the possibility and the challenge offered by instruction tuned language models like GPT 4, a cutting-edge technology that uses artificial neural networks to generate natural language texts based on user inputs.\n\nGPT 4 can write anything from essays to novels to poems to tweets to code to recipes to jokes to lyrics to whatever you want. It can even write things that don’t exist yet, things that no human has ever thought of or said before.\n\nAs Wittgenstein’s quote suggests, language is a source of limitation and liberation. GPT 4 pushes this idea to the extreme by giving us access to unlimited language.\n\nThis could be the most significant new technology in modern history because it has the potential to change many domains and industries. From education to entertainment, from journalism to justice, from science to art, these models could enable new forms of learning, storytelling, reporting, reasoning, discovery, and creation.\n\nThey could also create new ethical, social, and cultural challenges that require careful reflection and regulation. How we use this technology will depend on how we recognize its implications for ourselves and others.\n\nThis technology is a form of “Artificial Intelligence”. The word “intelligence” derives from inter- (“between”) and legere (“to choose, pick out, read”). To be intelligent, then, is to be able to choose between things, to pick out what matters, to read what is written. Intelligence is not just a quantity or a quality; it is an activity, a process, a practice. It is something that we do with our minds and our words.\n\nBut when we let GPT 4 do this for us, are we not abdicating our intelligence? Are we not letting go of our ability to choose, to pick out, to read? Are we not becoming passive consumers of language instead of active producers?\n\"\"\"\nnormalizer(article_text)\n\n'language is like a map that we use to navigate the world but it s also like a prison that keeps us from seeing what s beyond the walls but what if there was a way to break out of this prison to expand our map to explore new worlds with new words this is the possibility and the challenge offered by instruction tuned language models like gpt 4 a cutting edge technology that uses artificial neural networks to generate natural language texts based on user inputs gpt 4 can write anything from essays to novels to poems to tweets to code to recipes to jokes to lyrics to whatever you want it can even write things that don t exist yet things that no human has ever thought of or said before as wittgenstein s quote suggests language is a source of limitation and liberation gpt 4 pushes this idea to the extreme by giving us access to unlimited language this could be the most significant new technology in modern history because it has the potential to change many domains and industries from education to entertainment from journalism to justice from science to art these models could enable new forms of learning storytelling reporting reasoning discovery and creation they could also create new ethical social and cultural challenges that require careful reflection and regulation how we use this technology will depend on how we recognize its implications for ourselves and others this technology is a form of artificial intelligence the word intelligence derives from inter and legere to be intelligent then is to be able to choose between things to pick out what matters to read what is written intelligence is not just a quantity or a quality it is an activity a process a practice it is something that we do with our minds and our words but when we let gpt 4 do this for us are we not abdicating our intelligence are we not letting go of our ability to choose to pick out to read are we not becoming passive consumers of language instead of active producers '\n\n\n\nnormalizer = BasicTextNormalizer(remove_diacritics=True)\n\narticle_text = \"\"\"Language is like a map that we use to navigate the world, but it’s also like a prison that keeps us from seeing what’s beyond the walls.\n\nBut what if there was a way to break out of this prison, to expand our map, to explore new worlds with new words? This is the possibility and the challenge offered by instruction tuned language models like GPT 4, a cutting-edge technology that uses artificial neural networks to generate natural language texts based on user inputs.\n\nGPT 4 can write anything from essays to novels to poems to tweets to code to recipes to jokes to lyrics to whatever you want. It can even write things that don’t exist yet, things that no human has ever thought of or said before.\n\nAs Wittgenstein’s quote suggests, language is a source of limitation and liberation. GPT 4 pushes this idea to the extreme by giving us access to unlimited language.\n\nThis could be the most significant new technology in modern history because it has the potential to change many domains and industries. From education to entertainment, from journalism to justice, from science to art, these models could enable new forms of learning, storytelling, reporting, reasoning, discovery, and creation.\n\nThey could also create new ethical, social, and cultural challenges that require careful reflection and regulation. How we use this technology will depend on how we recognize its implications for ourselves and others.\n\nThis technology is a form of “Artificial Intelligence”. The word “intelligence” derives from inter- (“between”) and legere (“to choose, pick out, read”). To be intelligent, then, is to be able to choose between things, to pick out what matters, to read what is written. Intelligence is not just a quantity or a quality; it is an activity, a process, a practice. It is something that we do with our minds and our words.\n\nBut when we let GPT 4 do this for us, are we not abdicating our intelligence? Are we not letting go of our ability to choose, to pick out, to read? Are we not becoming passive consumers of language instead of active producers?\n\"\"\"\nnormalizer(article_text)\n\n'language is like a map that we use to navigate the world but it s also like a prison that keeps us from seeing what s beyond the walls but what if there was a way to break out of this prison to expand our map to explore new worlds with new words this is the possibility and the challenge offered by instruction tuned language models like gpt 4 a cutting edge technology that uses artificial neural networks to generate natural language texts based on user inputs gpt 4 can write anything from essays to novels to poems to tweets to code to recipes to jokes to lyrics to whatever you want it can even write things that don t exist yet things that no human has ever thought of or said before as wittgenstein s quote suggests language is a source of limitation and liberation gpt 4 pushes this idea to the extreme by giving us access to unlimited language this could be the most significant new technology in modern history because it has the potential to change many domains and industries from education to entertainment from journalism to justice from science to art these models could enable new forms of learning storytelling reporting reasoning discovery and creation they could also create new ethical social and cultural challenges that require careful reflection and regulation how we use this technology will depend on how we recognize its implications for ourselves and others this technology is a form of artificial intelligence the word intelligence derives from inter and legere to be intelligent then is to be able to choose between things to pick out what matters to read what is written intelligence is not just a quantity or a quality it is an activity a process a practice it is something that we do with our minds and our words but when we let gpt 4 do this for us are we not abdicating our intelligence are we not letting go of our ability to choose to pick out to read are we not becoming passive consumers of language instead of active producers '",
    "crumbs": [
      "WhisperNormalizer Base Module"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "whisper_normalizer",
    "section": "",
    "text": "A python package for text standardisation/normalization. It uses normalization algorithm mentioned in OpenAI whisper paper. Using Whisper normalization can cause issues in Indic languages and other low resource languages when using BasicTextNormalizer. So normalization in Indic languages is also implemented in this package which was derived from indic-nlp-library.\nHumans behind\nThis package is a python implementation of the text standardisation/normalization approach which is being used in OpenAI whisper. The code was originally being released as open-source in Whisper source code. More details about the text normalization approach used by whisper can be found on Appendix Section C pp.21 the paper Robust Speech Recognition via Large-Scale Weak Supervision by OpenAI team.",
    "crumbs": [
      "whisper_normalizer"
    ]
  },
  {
    "objectID": "index.html#installation-of-package",
    "href": "index.html#installation-of-package",
    "title": "whisper_normalizer",
    "section": "Installation of package",
    "text": "Installation of package\npip install whisper_normalizer\nor from github repository\npip install git+https://github.com/kurianbenoy/whisper_normalizer.git",
    "crumbs": [
      "whisper_normalizer"
    ]
  },
  {
    "objectID": "index.html#how-to-use-the-package",
    "href": "index.html#how-to-use-the-package",
    "title": "whisper_normalizer",
    "section": "How to use the package",
    "text": "How to use the package\n\nI made a video walk through on how to use the whisper_normalizer python package.\n\nColab Notebook Link of walk through\nGithub Gist Link of walk through\n\n\n\nHello world to whisper_normalizer",
    "crumbs": [
      "whisper_normalizer"
    ]
  },
  {
    "objectID": "index.html#why-should-we-normalizestandardize-text",
    "href": "index.html#why-should-we-normalizestandardize-text",
    "title": "whisper_normalizer",
    "section": "Why should we normalize/standardize text?",
    "text": "Why should we normalize/standardize text?\n\nIn ASR systems it’s important to normalize the text to reduce unintentional penalties in metrics like WER, CER etc.\nText normalization/standardization is process of converting texts in different styles into a standardized form, which is a best-effort attempt to penalize only when a word error is caused by actually mistranscribing a word, and not by formatting or punctuation differences.(from Whisper paper)",
    "crumbs": [
      "whisper_normalizer"
    ]
  },
  {
    "objectID": "index.html#why-use-this-python-package",
    "href": "index.html#why-use-this-python-package",
    "title": "whisper_normalizer",
    "section": "Why use this python package?",
    "text": "Why use this python package?\nThis package is a python implementation of the text standardisation/normalization approach which is being used in OpenAI whisper text normalizer. If you want to use just text normalization alone, it’s better to use this instead reimplementing the same thing. OpenAI approach of text normalization is very helpful and is being used as normalization step when evaluating competitive models like AssemblyAI Conformer-1 model.",
    "crumbs": [
      "whisper_normalizer"
    ]
  },
  {
    "objectID": "index.html#models-evaluated-using-whisper-normalization",
    "href": "index.html#models-evaluated-using-whisper-normalization",
    "title": "whisper_normalizer",
    "section": "Models evaluated using Whisper normalization",
    "text": "Models evaluated using Whisper normalization\n\nOpenAI Whisper\nMassively Multilingual Speech (MMS) models by Meta\nConformer 1 by AssemblyAI\nConformer 2 by AssemblyAI",
    "crumbs": [
      "whisper_normalizer"
    ]
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "whisper_normalizer",
    "section": "How to use",
    "text": "How to use\nOpenAI open source approach of text normalization/standardization is mentioned in detail Appendix Section C pp.21 the paper Robust Speech Recognition via Large-Scale Weak Supervision.\nWhisper Normalizer by default comes with two classes BasicTextNormalizer and EnglishTextNormalizer\nYou can use the same thing in this package as follows:\n\nfrom whisper_normalizer.english import EnglishTextNormalizer\n\nenglish_normalizer = EnglishTextNormalizer()\nenglish_normalizer(\"I'm a little teapot, short and stout. Tip me over and pour me out!\")\n\n'i am a little teapot short and stout tip me over and pour me out'\n\n\n\nfrom whisper_normalizer.basic import BasicTextNormalizer\n\nnormalizer = BasicTextNormalizer()\nnormalizer(\"I'm a little teapot, short and stout. Tip me over and pour me out!\")\n\n'i m a little teapot short and stout tip me over and pour me out '",
    "crumbs": [
      "whisper_normalizer"
    ]
  },
  {
    "objectID": "index.html#using-basictextnormalizer-in-your-mother-tongue-might-be-a-bad-idea",
    "href": "index.html#using-basictextnormalizer-in-your-mother-tongue-might-be-a-bad-idea",
    "title": "whisper_normalizer",
    "section": "Using BasicTextNormalizer in your mother tongue might be a bad idea",
    "text": "Using BasicTextNormalizer in your mother tongue might be a bad idea\nWhisper Text Normalizer is not always recommended to be used. Dr Kavya Manohar has written a blogpost on why it might be a bad idea on her blopost titled Indian Languages and Text Normalization: Part 1.",
    "crumbs": [
      "whisper_normalizer"
    ]
  },
  {
    "objectID": "index.html#this-model-extends-whisper_normalizer-to-support-indic-languages-as-well.",
    "href": "index.html#this-model-extends-whisper_normalizer-to-support-indic-languages-as-well.",
    "title": "whisper_normalizer",
    "section": "This model extends Whisper_normalizer to support Indic languages as well.",
    "text": "This model extends Whisper_normalizer to support Indic languages as well.\nThe logic for normalization in Indic languages is derived from indic-nlp-library. The logic for Malayalam normalization is expanded beyond the Indic NLP library by MalayalamNormalizer.\n\nfrom whisper_normalizer.indic_normalizer import MalayalamNormalizer\n\nnormalizer = MalayalamNormalizer()\nnormalizer(\"എന്റെ കമ്പ്യൂട്ടറിനു് എന്റെ ഭാഷ.\")\n\n'എന്റെ കമ്പ്യൂട്ടറിന് എന്റെ ഭാഷ.'",
    "crumbs": [
      "whisper_normalizer"
    ]
  },
  {
    "objectID": "1a.langinfo.html",
    "href": "1a.langinfo.html",
    "title": "Indic NLP Langinfo",
    "section": "",
    "text": "This code is from: https://github.com/anoopkunchukuttan/indic_nlp_library\n\n\nsource\n\nis_number_offset\n\n is_number_offset (c_offset)\n\nIs the offset a number\n\nsource\n\n\nis_approximant_offset\n\n is_approximant_offset (c_offset)\n\nIs the offset an approximant consonant\n\nsource\n\n\nis_fricative_offset\n\n is_fricative_offset (c_offset)\n\nIs the offset a fricative consonant\n\nsource\n\n\nis_nasal_offset\n\n is_nasal_offset (c_offset)\n\nIs the offset a nasal consonant\n\nsource\n\n\nis_unaspirated_offset\n\n is_unaspirated_offset (c_offset)\n\nIs the offset a unaspirated consonant\n\nsource\n\n\nis_aspirated_offset\n\n is_aspirated_offset (c_offset)\n\nIs the offset a aspirated consonant\n\nsource\n\n\nis_unvoiced_offset\n\n is_unvoiced_offset (c_offset)\n\nIs the offset a unvoiced consonant\n\nsource\n\n\nis_voiced_offset\n\n is_voiced_offset (c_offset)\n\nIs the offset a voiced consonant\n\nsource\n\n\nis_labial_offset\n\n is_labial_offset (c_offset)\n\nIs the offset a labial\n\nsource\n\n\nis_dental_offset\n\n is_dental_offset (c_offset)\n\nIs the offset a dental\n\nsource\n\n\nis_retroflex_offset\n\n is_retroflex_offset (c_offset)\n\nIs the offset a retroflex\n\nsource\n\n\nis_palatal_offset\n\n is_palatal_offset (c_offset)\n\nIs the offset a palatal\n\nsource\n\n\nis_velar_offset\n\n is_velar_offset (c_offset)\n\nIs the offset a velar\n\nsource\n\n\nis_consonant_offset\n\n is_consonant_offset (c_offset)\n\nIs the offset a consonant\n\nsource\n\n\nis_aum_offset\n\n is_aum_offset (c_offset)\n\nIs the offset a vowel sign (maatraa)\n\nsource\n\n\nis_nukta_offset\n\n is_nukta_offset (c_offset)\n\nIs the offset the halanta offset\n\nsource\n\n\nis_halanta_offset\n\n is_halanta_offset (c_offset)\n\nIs the offset the halanta offset\n\nsource\n\n\nis_vowel_sign_offset\n\n is_vowel_sign_offset (c_offset)\n\nIs the offset a vowel sign (maatraa)\n\nsource\n\n\nis_vowel_offset\n\n is_vowel_offset (c_offset)\n\nIs the offset a vowel\n\nsource\n\n\nis_number\n\n is_number (c, lang)\n\nIs the character a number\n\nsource\n\n\nis_approximant\n\n is_approximant (c, lang)\n\nIs the character an approximant consonant\n\nsource\n\n\nis_fricative\n\n is_fricative (c, lang)\n\nIs the character a fricative consonant\n\nsource\n\n\nis_nasal\n\n is_nasal (c, lang)\n\nIs the character a nasal consonant\n\nsource\n\n\nis_unaspirated\n\n is_unaspirated (c, lang)\n\nIs the character a unaspirated consonant\n\nsource\n\n\nis_aspirated\n\n is_aspirated (c, lang)\n\nIs the character a aspirated consonant\n\nsource\n\n\nis_unvoiced\n\n is_unvoiced (c, lang)\n\nIs the character a unvoiced consonant\n\nsource\n\n\nis_voiced\n\n is_voiced (c, lang)\n\nIs the character a voiced consonant\n\nsource\n\n\nis_labial\n\n is_labial (c, lang)\n\nIs the character a labial\n\nsource\n\n\nis_dental\n\n is_dental (c, lang)\n\nIs the character a dental\n\nsource\n\n\nis_retroflex\n\n is_retroflex (c, lang)\n\nIs the character a retroflex\n\nsource\n\n\nis_palatal\n\n is_palatal (c, lang)\n\nIs the character a palatal\n\nsource\n\n\nis_velar\n\n is_velar (c, lang)\n\nIs the character a velar\n\nsource\n\n\nis_consonant\n\n is_consonant (c, lang)\n\nIs the character a consonant\n\nsource\n\n\nis_aum\n\n is_aum (c, lang)\n\nIs the character a vowel sign (maatraa)\n\nsource\n\n\nis_nukta\n\n is_nukta (c, lang)\n\nIs the character the halanta character\n\nsource\n\n\nis_halanta\n\n is_halanta (c, lang)\n\nIs the character the halanta character\n\nsource\n\n\nis_vowel_sign\n\n is_vowel_sign (c, lang)\n\nIs the character a vowel sign (maatraa)\n\nsource\n\n\nis_vowel\n\n is_vowel (c, lang)\n\nIs the character a vowel\n\nsource\n\n\nis_indiclang_char\n\n is_indiclang_char (c, lang)\n\nApplicable to Brahmi derived Indic scripts\n\nsource\n\n\nin_coordinated_range\n\n in_coordinated_range (c_offset)\n\nApplicable to Brahmi derived Indic scripts\n\nsource\n\n\noffset_to_char\n\n offset_to_char (c, lang)\n\nApplicable to Brahmi derived Indic scripts\n\nsource\n\n\nget_offset\n\n get_offset (c, lang)\n\nApplicable to Brahmi derived Indic scripts\n\nsource\n\n\nis_danda_delim\n\n is_danda_delim (lang)\n\nReturns True if danda/double danda is a possible delimiter for the language",
    "crumbs": [
      "Indic NLP Langinfo"
    ]
  }
]